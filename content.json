{"meta":{"title":"杨同学的日常闲扯","subtitle":"杨同学的日常闲扯","description":"个人技术博客，Python、算法、机器学习、深度学习","author":"杨同学","url":"https://imzry.github.io","root":"/"},"pages":[],"posts":[{"title":"配置本地访问远程Linux系统服务器的jupyter notebook","slug":"配置本地访问远程Linux系统服务器的jupyter-notebook","date":"2019-07-23T11:22:28.000Z","updated":"2019-07-26T08:32:52.218Z","comments":true,"path":"2019/07/23/配置本地访问远程Linux系统服务器的jupyter-notebook/","link":"","permalink":"https://imzry.github.io/2019/07/23/配置本地访问远程Linux系统服务器的jupyter-notebook/","excerpt":"","text":"环境情况 远程服务器上配置了anaconda 本地主机没有安装anaconda（其实安不安装都无所谓，有浏览器就行） 配置步骤如下 登录远程服务器 生成配置文件 jupyter notebook --generate-config 生成密码 输入ipython打开ipython生成密钥： 12345In [1]: from notebook.auth import passwdIn [2]: passwd()Enter password:Verify password:Out[2]: 'sha1:ce23d945972f:34769685a7ccd3d08c84a18c63968a41f1140274' #这段是密钥 把生成的密钥’sha1:ce2…’复制下来后面用，password是远程登录时需要输入的密码，要记住。 修改配置文件 使用vim打开配置文件 vim ~/.jupyter/jupyter_notebook_config.py 修改如下地方： 123456c.NotebookApp.ip = '*'c.NotebookApp.password = u'sha:ce...刚才复制的那个密文'c.NotebookApp.open_browser = Falsec.NotebookApp.port = 8888 #随便指定一个端口，但是要记住c.NotebookApp.allow_remote_access = Truec.NotebookApp.notebook_dir = u'目录' #这个是根目录，不想配置就不配置，默认是用户家目录 启动jupyter notebook 正常启动： jupyter notebook 但是我们可能通常想要在后台启动jupyter，然后关闭终端，在本地电脑上用浏览器访问： nohup jupyter notebook &amp; 远程访问 在本地打开浏览器访问http://address_of_remote:8888就可以访问jupyter的登录界面了，输入密码就可以正常登录了。 意外情况有些服务器可能只开放一个对外的端口，但是我们通过终端访问服务器需要一个对外端口，开启jupyter服务又需要一个端口，这样就需要同时占用两个端口才行。举个栗子，服务器为了保证安全性只开放了一个对外的端口，22号端口，我们使用终端通过22号端口登录到服务器上打开jupyter，jupyter创建的端口是8888号，但是服务器没有对外开放8888号端口，所以即使打开了jupyter，外面也无法正常访问。如果把jupyter的端口号改为22号，由于我们登录终端的时候正在占用22号，所以jupyter就会提示端口已被占用，无法创建。网上有很多教程说可以通过修改防火墙设置来开放端口，修改防火墙设置一般都需要管理员权限，但是通常我们使用服务器的时候大多数情况下是不可能有管理员权限的，这时候我们可以使用端口映射来解决这个问题。 首先登录终端打开jupyter，这是根据配置信息jupyter占用的是8888端口。 然后我们在本地上使用命令行输入： ssh -N -f -L localhost:9999:localhost:8888 -p 端口号 username@远程地址 例如ssh -N -f -L localhost:9999:localhost:8888 -p 22 yzr@202.48.29.23 这里说明一下：locahost:9999是指本地地址，localhost:8888是指远程地址，其中8888是jupyter notebook中设置的端口号，-p 22是指登录服务器的端口号 后面是用户名和服务器ip。 打开浏览器，输入localhost:9999就可以看到jupyter notebook的登录界面了。 这里原理上就是将服务器上的8888端口映射到本机的9999端口。","categories":[{"name":"Python","slug":"Python","permalink":"https://imzry.github.io/categories/Python/"}],"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"https://imzry.github.io/tags/DeepLearning/"},{"name":"jupyter","slug":"jupyter","permalink":"https://imzry.github.io/tags/jupyter/"},{"name":"Python","slug":"Python","permalink":"https://imzry.github.io/tags/Python/"}]},{"title":"论文翻译：HetConv-Heterogeneous Kernel-Based Convolutions for Deep CNNs","slug":"论文翻译：HetConv-Heterogeneous Kernel-Based Convolutions for Deep CNNs","date":"2019-06-06T05:57:02.000Z","updated":"2019-07-27T02:30:06.967Z","comments":true,"path":"2019/06/06/论文翻译：HetConv-Heterogeneous Kernel-Based Convolutions for Deep CNNs/","link":"","permalink":"https://imzry.github.io/2019/06/06/论文翻译：HetConv-Heterogeneous Kernel-Based Convolutions for Deep CNNs/","excerpt":"","text":"Abstract我们提出了一种新颖的深度学习架构，其中卷积操作利用了异构内核。与标准卷积运算相比，所提出的HetConv（基于异构内核的卷积）减少了计算（FLOPs）和参数的数量，同时仍保持表示效率。为了证明我们提出的卷积的有效性，我们在标准卷积神经网络（CNN）架构上提供了广泛的实验结果，如VGG和ResNet。 我们发现在用我们提出的HetConv滤波器替换这些架构中的标准卷积滤波器后，我们实现了基于3X到8X FLOPs的速度提升，同时仍然保持（有时提高）精度。 我们还将我们提出的卷积与组/深度方式的卷积进行比较，并表明它可以以更高的精度实现更多的FLOPs减少。 1. Introduction卷积神经网络在视觉和NLP等领域表现出了显著的性能。进一步提高性能的总趋势使模型更加复杂和深入。随着网络的深入，通过增加模型复杂度来提高精度并不是免费的；它伴随着计算量(FLOPs)的大幅增加。因此，人们提出了各种卷积运算/卷积滤波器，以减少对模型的FLOPs，提高模型的效率。 现有的卷积滤波器可以粗略地分为三类：1-深度卷积滤波器执行深度卷积（DWC），2-逐点卷积滤波器执行逐点卷积（PWC）和3-组循环卷积滤波器执行 分组卷积（GWC）。 大多数最近的架构使用这些卷积滤波器的组合来使模型有效。使用这些卷积（例如，DWC，PWC和GWC），许多流行的模型已经探索了新的架构来减少FLOPs。但是，设计新架构需要大量工作才能找到最佳的滤波器组合，从而实现最小的FLOPs。 另一种提高模型效率的流行方法是使用模型压缩。模型压缩大致可分为三类:连接剪枝、滤波器剪枝和量化。 在滤波器剪枝中，其思想是剪枝模型中贡献最小的筛选器，在删除此筛选器/连接之后，通常对模型进行微调以保持其性能。在修剪模型时，我们需要一个预先训练的模型(可能需要一个计算上昂贵的训练作为预处理步骤)，然后我们丢弃贡献最小的过滤器。因此，这是一个非常昂贵和棘手的过程。因此，使用有效的卷积滤波器或卷积运算来设计一个有效的架构是比剪枝更流行的方法。这并不需要昂贵的训练，然后修剪，因为训练是从头开始有效地完成。 使用有效的卷积滤波器，有两个不同的目标。一种工作侧重于设计具有最小FLOPs而同时降低精度的架构。这些工作重点是开发物联网/低端设备的模型。这些模型的精度较低，因此必须搜索最佳模型，以在精度和FLOPs之间建立平衡。因此，在FLOP和模型精度之间存在权衡。 另一组工作侧重于提高准确性，同时保持模型FLOPs与原始架构相同。最近的架构，如Inception，RexNetXt和Xception就是这类工作的例子。他们的目标是使用有效的卷积滤波器设计更复杂的模型，同时保持FLOPs与基本模型相同。通常期望更复杂的模型可以学习更好的特征，从而获得更好的准确性。但是，这些方法并不专注于设计新架构，而主要是在标准基础架构中使用现有的高效过滤器。因此，这些工作保持层数和体系结构与基础模型相同，并增加每层上的过滤器，使其不增加FLOPs。 与这两种方法相比，我们工作的主要重点是通过设计新内核来减少给定模型/体系结构的FLOP，而不会影响精度损失。 在实验上我们发现所提出的方法具有比现有技术修剪方法低得多的FLOPs，同时保持基础模型/架构的准确性。修剪方法非常昂贵，并且显示出实现FLOPs压缩的准确性显着下降。 在提出的方法中，我们选择了一种不同的策略来提高现有模型的效率，同时又不牺牲精度。架构搜索需要多年的研究才能得到优化的架构。因此，我们没有设计一个新的高效的架构，而是设计了一个高效的卷积运算(卷积滤波器)，它可以直接插入到任何现有的标准架构中以减少FLOPs。为了实现这一点，我们提出了一种新型的卷积——异构卷积。 卷积运算可以根据核的类型分为两类： 使用传统卷积滤波器的同构卷积(例如标准卷积、群卷积、深度卷积、点卷积)。同构卷积可以用同构滤波器来实现。如果一个过滤器包含所有大小相同的内核，那么它就是同构的（例如，在一个$3\\times 3\\times 256$ CONV2D过滤器中，所有256个内核的大小都是$3 \\times 3$）。 异构卷积使用异构卷积滤波器(HetConv)。如果一个过滤器包含不同大小的内核，那么它就是异构的(例如，在HetConv过滤器中，256个内核中有一些内核大小为$3\\times 3$，其余的内核大小为$1 \\times 1$)。 在深度CNN中使用异构滤波器克服了现有基于高效架构搜索和模型压缩的方法的局限性。最新的高效架构之一MobileNet使用深度和点卷积。标准的卷积层被两个卷积层替换，因此它有更多的延迟（延迟1，延迟也可以简单的理解为速度慢于基准模型的多少）。有关延迟的详细信息，请参阅- 3.3节和图4。但是我们提出的HetConv具有与原始架构相同的延迟（延迟为零），而不像具有大于零的延迟。 与高精度下降的模型压缩相比，我们的方法与ResNet和VGGNet等标准模型的最新结果相比具有很强的竞争力。 使用HetConv过滤器，我们可以从头开始训练我们的模型，而不像需要预训练模型的修剪方法，而不会牺牲准确性。 如果我们增加FLOPs修剪的程度，修剪方法也会遭受严重的精确度下降。 使用提出的Het-Conv滤波器，与FLOPs修剪方法相比，我们拥有关于FLOPs的最新结果。 此外，修剪过程效率低，因为修剪后需要花费大量时间进行训练和微调。 我们的方法非常高效，并且在从头开始训练时，与原始模型相比，提供了类似的结果。 据我们所知，这是第一个异构的卷积/过滤器。这种异构设计有助于提高现有架构的效率（FLOPs降低），而不会牺牲精度。 我们在ResNet，VGG-16等不同架构上进行了大量实验，只需将原来的滤波器替换为我们提出的滤波器即可。 我们发现，在不牺牲这些模型的准确性的情况下，我们将FLOPs的高度降低（3倍到8倍）。与现有的修剪方法相比，这些FLOPs减少甚至更好。 我们的主要贡献如下： 我们设计了一个高效的异构卷积滤波器，它可以插入到任何现有的架构中，在不牺牲精度的前提下，提高架构的效率(将FLOPs减少3到8倍)。 提出的HetConv滤波器的设计方式是零延迟。因此，从输入到输出的延迟可以忽略不计。 2. Related Work最近深度神经网络的成功取决于模型设计。为了实现最小的错误率，模型变得越来越复杂。 复杂而深入的架构包含数百万个参数，需要数十亿次FLOP（计算）。 这些模型需要具有高端规格的机器，并且这些类型的架构在低计算资源上效率非常低。 这引起了人们对设计高效模型的兴趣。提高模型效率的工作可分为两部分。 2.1. Efficient Convolutional Filter(高效的卷积过滤器)为了设计高效的卷积滤波器，近年来提出了几种新型的卷积滤波器。其中分组卷积(GWC)、深度卷积(DWC)[38]和点态卷积(PWC)是常用的卷积滤波器。它们被广泛用于设计高效的体系结构。GoogleNet使用inception模块和不规则的堆叠架构。Inception模块使用GWC和PWC来减少FLOPs。ResNet使用瓶颈结构来设计具有剩余连接的高效架构。它们使用PWC和标准卷积，有助于在不增加模型参数的情况下更深入，并减少FLOP爆炸。因此，与VGG相比，他们可以设计更深入的架构。ResNetxt使用ResNet架构，他们用GWC和PWC划分每一层。因此，在不增加FLOP的情况下，它们可以增加基数1.它们表明增加基数比更深或更宽的网络更有效。SENet设计了一种新的连接，它为每个输出特征映射赋予了权重，虽然FLOPs略有增加，但性能却有所提升。 MobileNet是另一种流行的架构，专为包含DWC和PWC的物联网设备而设计。这种架构在FLOP方面非常轻便且高效。FLOP的减少不是免费的，并且与最先进的模型相比，精度下降的成本也随之降低。在同一层使用不同类型的卷积滤波器，但由于每个过滤器中存在相同类型的内核，所以每个滤波器执行的卷积都是同构的。在相同层使用不同类型的卷积滤波器也有助于减少参数FLOP。在我们提出的卷积中，由于每个滤波器中存在不同类型的内核，卷积操作是异构的。 2.2. Model Compression（模型的压缩）另一种提高CNN效率的流行方法是模型压缩。这些可以分为:1-连接剪枝，2-过滤器剪枝和3位压缩。与其他方法相比，滤波器剪枝方法更有效，并且在FLOPs方面具有较高的压缩率。此外，过滤器修剪方法不需要任何特殊的硬件/软件支持(稀疏库)。 在滤波器剪枝中，大部分工作都是根据一定的准则计算滤波器的重要性，然后对其进行剪枝，然后进行再训练以恢复精度下降。使用L1范数作为排名过滤器的度量。但是，剪枝是在预先训练的模型上完成的，包括迭代训练和剪枝，这是昂贵的。此外，如果触发器剪枝的程度增加，则滤波器剪枝的精度会急剧下降。 3. Proposed Method（提出的方法）在这项工作中，我们提出了一种新颖的滤波器/卷积（Het-Conv），它包含异构内核（例如，少数内核的大小为$3 \\times 3$，其他内核可能为$1 \\times 1$），以减少现有模型的FLOPs。 与原始模型的精度相同。这与由均匀内核（例如全部$3 \\times 3$或全部$5 \\times 5$）组成的标准卷积滤波器非常不同。异构滤波器在FLOPs方面非常有效。它可以近似为分组卷积滤波器（GWC）和逐点卷积滤波器（PWC）的组合滤波器。为了减少卷积层的FLOPs，我们通常将其替换为两层或更多层（GWC / DWC和PWC），但它会增加延迟，因为下一层的输入是前一层的输出。因此，必须按顺序完成所有计算以获得正确的输出。相比之下，我们提出的HetConv具有相同的延迟。标准滤波器和HetConv滤波器之间的差异如图1和图2所示。 图1 标准卷积过滤器（同构）和异构卷积过滤器（HetConv）之间的诧异。其中M是指输入深度（输入通道的数量），P是指part（控制卷积过滤器中不同类型的核的数量）。在M个核中，$\\frac MP$核的大小是$3×3$，其余的都是$1×1$。 图2 将所提出的卷积滤波器(HetConv)与其他有效卷积滤波器进行比较。我们的异构过滤器的延迟为零，而其他过滤器(GWC+PWC或DWC+PWC)的延迟为一个单元。 在标准卷积层中，假设输入(输入特征图)的大小为$D_i\\times D_i\\times M$。其中$D_i$为输入的正方形特征图空间宽度和高度，$M$为输入深度(输入通道数)。还要考虑$D_o\\times D_o\\times N$是输出特性映射。这里$D_o$是输出的正方形特征图空间宽度和高度，$N$是输出深度(输出通道数)。应用$K\\times K\\times M$大小的N个滤波器得到输出特征图。这里K是内核大小。因此，这一$L$层的总计算成本为： FL_S=D_o\\times D_o \\times M \\times N \\times K \\times K \\tag{1}由式(1)可以看出，计算代价与核大小(K)、feature map大小、输入通道M和输出通道n有关。这种计算代价非常高，可以通过精心设计新的卷积运算进一步降低。为了减少高计算量，提出了各种卷积，如DWC、PWC和GWC，这些卷积在许多最近的架构中被使用来减少FLOPs，但它们都增加了延迟。 标准卷积运算和一些最近的卷积运算使用同构核(即，对于整个过滤器，每个内核的大小相同)。为了提高效率，我们使用了异构内核。对于同一个过滤器，它包含不同大小的内核。请参考图3来可视化特定层l上的所有过滤器。我们定义P部分，它控制卷积过滤器中不同类型内核的数量。对于第P部分，总内核中的$\\frac{1}{P}$部分为$K\\times K$大小，其余部分$(1-\\frac1P)$为$1\\times 1$大小。为了更好地理解，让我们举个例子，在一个$3\\times3\\times 256$标准CONV2D过滤器中，如果您将$(1-\\frac1P)\\times 256$、$3\\times 3$个内核替换为$1\\times 1$(沿着中轴)，您将得到一个带有$P$部分的HetConv过滤器。请参见图1和图2。 图3 第$L$层卷积滤波器：使用异构内核的卷积滤波器(HetConv)。在图中，每个通道由大小为$3 \\times 3$和$1\\times 1$的异构内核组成。在标准卷积滤波器中，用$1\\times 1$的核替换$3 \\times 3$的核，在保持精度的同时，大大减少了误操作。特定层的过滤器以移位的方式排列(即，如果第一个过滤器从第一个位置启动$3\\times 3$内核，那么第二个过滤器从第二个位置启动$3 \\times 3$内核，以此类推)。 在层$L$上有$P$部分的Hetconv滤波器中，$k\\times k$大小的核的计算成本如下所示： FL_K=\\frac{(D_o \\times D_o \\times M \\times N \\times K \\times K)}{P} \\tag{2}它降低了P倍的成本，因为我们现在只有$\\frac MP$个$K \\times K$大小的核。 其余的$(M-\\frac MP)$内核大小为$1\\times 1$。剩余的$1\\times 1$个内核的计算成本为： FL_1 = (D_o \\times D_o \\times N) \\times (M - \\frac MP) \\tag{3}因此，第$L$层的总计算成本为： FL_{HC} = FL_K + FL_1 \\tag{4}与标准卷积相比，计算的总减少量（R）可表示为： R_{HetConv} = \\frac {FL_K + FL_1}{FL_S} =\\frac1P + \\frac{1-\\frac1P}{K^2} \\tag{5}在方程5中，如果我们令$P = 1$，那么它就变成了标准卷积滤波器。 通过将某些通道上的过滤器大小从$3\\times 3$减小到$1 \\times 1$，我们正在减小过滤器的空间范围。但是，通过在某些信道上保持$3\\times 3$的大小，我们可以确保滤波器覆盖了某些信道上的空间相关性，并且不需要在所有信道上都具有相同的空间相关性。我们在实验部分观察到，通过这样做，我们可以获得与同构过滤器相似的精度。另一方面，如果我们避免并保留所有通道上的$1\\times1$滤波器大小，那么我们就不会覆盖必要的空间相关信息，并且精度会受到影响。 3.1. Comparision with DepthWise followed by PointWise Convolution（比较深度卷积和点卷积）在极端情况下，HetConv中$P=M$时，HetConv可以与DWC+PWC(深度卷积后点卷积)进行比较。MobileNet使用这种类型的卷积。虽然MobileNet比我们的极端情况有更多的FLOPs与更多的延迟，因为MobileNet有一个延迟。 对于第$L$层，DWC+PWC (MobileNet)的总FLOPs数可以计算为： FL_{MobNet} =D_o \\times D_o \\times M \\times K \\times K + M \\times N \\times D_o \\times D_o \\tag{6}因此总的计算量比标准卷积减少了： R_{MobNet}=\\frac{FL_{MobNet}}{FL_S}=\\frac 1N + \\frac{1}{K^2} \\tag{7}从公式5可以清楚地看出，我们可以改变$P$部分的值来在精度和FLOPs之间进行权衡。 如果我们减小$P$值，产生的卷积将更接近标准卷积。 为了显示所提出的HetConv滤波器的有效性，我们在实验部分中显示了结果，其中HetConv使用类似的FLOP实现了明显更好的精度。 在$P = M$的极端情况下，由公式5和7(对于MobileNet $N = M$)，我们可以得出结论： \\frac 1M + \\frac{(1-\\frac1M)}{K^2}< \\frac 1M + \\frac{1}{K^2} \\tag{8}与标准卷积相比计算量的总减少： Speedup = \\frac{1}{Reduction} \\tag{9}因此，从公式8可以看出，MobileNet比我们的方法需要更多的计算。在我们的HetConv中，延迟为零，而MobileNet的延迟为1。在这种极端情况下，我们的精度明显高于MobileNet(请参阅实验部分)。 3.2. Comparision with GroupWise followed by PointWise Convolution（与GroupWise比较，然后是PointWise Convolution）对于组大小为$G$的群向卷积和点态卷积(GWC+PWC)，第$L$层的GWC+PWC总的FLOPs次数可以计算为： FL_G = \\frac{(D_o \\times D_o \\times M \\times N \\times K \\times K)}{G+ M \\times N \\times D_o \\times D_o} \\tag{10}因此计算的总减少与标准的卷积比较： R_{Group} = \\frac {FL_G}{FL_S} = \\frac1G + \\frac{1}{K^2} \\tag{11}同样的，当$P=G$时，由公式5和11得到： \\frac 1P + \\frac{(1-\\frac1P)}{K^2}","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://imzry.github.io/categories/论文阅读/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://imzry.github.io/tags/深度学习/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"https://imzry.github.io/tags/DeepLearning/"},{"name":"卷积神经网络","slug":"卷积神经网络","permalink":"https://imzry.github.io/tags/卷积神经网络/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-01-02T01:34:05.000Z","updated":"2019-07-27T02:39:31.538Z","comments":true,"path":"2019/01/02/hello-world/","link":"","permalink":"https://imzry.github.io/2019/01/02/hello-world/","excerpt":"","text":"欢迎来到Hexo！这是你的第一篇文章。查看文档以获取更多信息。 如果您在使用Hexo时遇到任何问题，可以在故障排除中找到答案，或者您可以在GitHub上询问我。 快速开始创建一个新帖子1$ hexo new \"我的新文章\" 更多信息：写作 运行服务器1$ hexo server 更多信息：服务器 生成静态文件1$ hexo generate 更多信息：生成 部署到远程站点1$ hexo deploy 更多信息：部署","categories":[],"tags":[]}]}